{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da75596e",
   "metadata": {},
   "source": [
    "Introduction:\n",
    "The basis for our code comes from David Pollard's 1982 paper, A simple ice sheet model yields realistic 100 glacial cycles. Pollard wanted to build of the previous work of Birchfield et al. and Oerlemans in order to produce an accurate model of the 100 kyr ice cycle. Pollard's goal was to create a model that that would closely follow the records of ice volume in glaciers for the past 700 kyr. Pollard's model differs from other previous models in the fact that it takes into account both topography and possible calving. These additions led to a model that matched the 700 kyr records more closely than any other model up to that point in time. It's important that scientists try to get their models to closely follow past data, because it means that said models will likely be more accurate in predicting the future. Glaciers are an incredibly important part of the earth’s climate system, and as global temperatures rise it has become clear that glaciers are shrinking at an alarming rate. The ability to accurately model glaciers is more important now than ever due to the effects of climate change. The main numerical method used in the paper is the Newton-Raphson method, which is applied to two equations separately. TALK ABOUT OTHER MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3616d0f",
   "metadata": {},
   "source": [
    "Equations: \n",
    "Northern hemisphere glacial cycles are quite complex and depend on quite a lot of variables. From historical records it can be observed that there is a dominant cycle of glacial ice volume that occurs over an 100 kyr period. The main equation used by Pollard is a simplified diffusion equation for ice thickness which is as follows:\n",
    "\n",
    "$$\\frac{\\partial h}{\\partial t} = A \\frac{\\partial}{\\partial x}\\left[h^{\\alpha} \\left|\\frac{\\partial (h + h')}{\\partial x}\\right|^{\\beta} \\frac{\\partial (h + h')}{\\partial x}\\right] + G(h + h', x, \\text{orbit})$$\n",
    "\n",
    "This is quite a long formula, but once each term is defined it becomes much easier to understand. The variable t is time while x is the distance from north to south. h' is defined as the elevation of the bedrock surface above a fixed point, which in this case is the mean sea level from 1982. This formula is also made up of some constants, A is one such constant that is equal to 5.77e-4 1/m^3*yr. Alpha and beta are also constants, equal to 5 and 2 respectively. The northern boundary of the model is 74° N while the southern boundary is taken to be 30° N. At these points h = 0 which is to prevent ice formation in the arctic and tropics. G is the net annual mass balance on the ice surface and is dependent on a separate set of equations from Oerlemans(SITE): \n",
    "\n",
    "$$\n",
    "G = \\begin{cases}\n",
    "a(h + h' - E) - b(h + h' - E)^2 & \\text{if } h + h' - E \\leq 1{,}500 \\text{ m} \\\\\n",
    "0.56 & \\text{if } h + h' - E > 1{,}500 \\text{ m}\n",
    "\\end{cases} \\text{ m yr}^{-1}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "This equation also is built upon some constants, being a and b. a is equal to 0.81 * 10^-3 1/yr, while b is 0.30 * 10^-6 1/m*yr. E is the equilibrium altitude, and is the value that controls the value of G. E has a constant slope and is dependent on its own equation E = E0(x) + k * dQ. E0 is the present equilibrium line and dQ is the difference in the summer half year insolation from 55° N from the present, which in this case is 1982. K is the isolation sensitivity and like E0, is a value that is changed each run to yield different results.\n",
    "\n",
    "There is a third main equation that is used in this one-dimensional model, and this equation is related to the change in bedrock due to the change in ice load. The Pollard states that at the time of the paper there wasn’t a consensus on what kind of model would be best for this, so he chose to use a “thin-channel model”. The equation is as follows:\n",
    "\n",
    "$$\\frac{\\partial h'}{\\partial t} = \\nu \\frac{\\partial^2}{\\partial x^2}[h' - h'_0(x) + rh]$$\n",
    "\n",
    "This equation seems to be quite simple; however, the \"v\" term in the equation is itself quite complicated. V is equal to ρa * g * H^3 / Nη, with the simplest of these variables being g, the gravitational constant one the surface of earth. H is the mean thickness along a channel while η is the dynamic viscosity of said channel. N is either 3 or 12 depending on the requirements at the base of the lithosphere. r is the ratio of ice density (ρi) to rock density (ρa). h’0(x) is the surface topography that would occur without ice, and is the variable that determines the boundary conditions for this equation. Pollard chose to have h’ = h’0 such that the latitudinal bounds are 74° N and 30° N. \n",
    "\n",
    "The main variables that will be modified between each run are the parameters that Pollard modified, those being, E0, k, r, v, and h'0(x). The main limitation of these eqautions is that they only account for ice thickness running north to south. Pollard rectifies this by multiplying by an east-west ice sheet dimenstion of about 3000 km to compute the volume. ADD MORE HERE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c265fb05",
   "metadata": {},
   "source": [
    "Numerical Methods:\n",
    "Need to elabolrate on this more, haven't had time while working on the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d5c687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup (Imports and Variables)\n",
    "# NOTE: All units of distance are in METERS\n",
    "# 1 degree latiture ~= 111,000 m\n",
    "# Since all h values are in meters, it is better to use meters instead of degrees when solving\\\n",
    "# all relevant constant/intital values are stored in the values dictionary\n",
    "# code DOES NOT RUN RIGHT NOW, need to fix intial values as well as the main loop, ice density function also needs a rework\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "from scipy.sparse import diags\n",
    "\n",
    "\n",
    "def initialize(numberPoints, dt):\n",
    "\n",
    "    values = {}\n",
    "\n",
    "    values['n'] = numberPoints\n",
    "    values['dt'] = dt # years\n",
    "\n",
    "    values['alpha'] = 5\n",
    "    values['beta'] = 2\n",
    "    values['A'] = 5.77 * 10 ** -4\n",
    "    values['lat_max'] = 74\n",
    "    values['lat_min'] = 30\n",
    "\n",
    "    values['a'] = 0.81 * 10 ** -3\n",
    "    values['b'] = 0.30 * 10 ** -6\n",
    "    values['r'] = 0.3\n",
    "    values['k'] = 17\n",
    "    values['nu'] = 100\n",
    "    values['v'] = 100000 * 1000 # km2 / yr, converted to meters \n",
    "\n",
    "    values['dx'] = (74-30) / (numberPoints - 1)\n",
    "    values['dx_m'] = values['dx'] * 111000\n",
    "\n",
    "\n",
    "    values['h'] = np.zeros(numberPoints)\n",
    "    values[\"h_prime\"] = np.zeros(numberPoints)\n",
    "    values['lat'] = np.linspace(30, 74, numberPoints)\n",
    "    values['E0'] = 550 + 111 * (values['lat']-70) # from paper, this math might be wrong, will probably have to change\n",
    "    values[\"h_prime0\"] = np.interp(values['lat'], np.array([30, 40, 66, 70, 74]), np.array([400, 400, 200, 850, -500])) #generating topography\n",
    "\n",
    "    return values\n",
    "\n",
    "v = initialize(80, 50) # Test values from paper, 80 points and 50 year timesteps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbff7182",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bedrockM (size): #Creating the matricies that will be used to solve equation 3, DOES NOT NEED TO BE CALLED MORE THAN ONCE\n",
    "    arr_size = size\n",
    "    cD = v['v'] * v['dt'] / v['dx_m'] ** 2\n",
    "    ML_Data = np.array([[-0.5*cD]*arr_size,[1+cD]*arr_size,[-0.5*cD]*arr_size])\n",
    "    MLdiag = np.array([-1,0,1])\n",
    "    ML = sp.sparse.spdiags(ML_Data, MLdiag, arr_size, arr_size).toarray()\n",
    "\n",
    "    MR_Data = np.array([[0.5*cD]*arr_size,[1-cD]*arr_size,[0.5*cD]*arr_size])\n",
    "    MRdiag = np.array([-1,0,1])\n",
    "    MR = sp.sparse.spdiags(MR_Data, MRdiag, arr_size, arr_size).toarray()\n",
    "\n",
    "    # Applying Dirichlet conditions to arrays\n",
    "    # not sure why the entire row needs to be zero, had to look it up to get this function working, LOOK INTO THIS\n",
    "    ML[0, :] = 0\n",
    "    ML[0, 0] = 1\n",
    "    MR[0, :] = 0\n",
    "    MR[0, 0] = 1\n",
    "\n",
    "    ML[arr_size-1, :] = 0\n",
    "    ML[arr_size-1, arr_size-1] = 1\n",
    "    MR[arr_size-1, :] = 0\n",
    "    MR[arr_size-1, arr_size-1] = 1\n",
    "\n",
    "\n",
    "    return ML, MR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2647f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mass balance function, solving for G, likely not going to work first time, dQ is a mess to calculate so\n",
    "# I wrote a placeholder function for now, will have more time when I'm not dying from exams to fix this.\n",
    "\n",
    "def massBal(h, h_prime, timestep):\n",
    "    dQ = 50 * np.sin(2*np.pi * timestep / 100000)\n",
    "    elevation = h + h_prime\n",
    "    G = np.zeros(len(elevation))\n",
    "    E = v['E0'] + v['k'] * dQ\n",
    "    for i in range(len(elevation)):\n",
    "        if elevation[i] - E[i] <= 1500:\n",
    "            #quadratic function\n",
    "            G[i] = v['a'] * (elevation[i] - E[i]) - v['b'] * (elevation[i] - E[i]) ** 2\n",
    "        elif elevation[i] - E[i] > 1500:\n",
    "            #constant\n",
    "            G[i] = 0.56\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d07fe37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iceDensity(h, h_prime):\n",
    "    noZeroMath = 1e-10 # prevents h and the gradient from being zero, cause that would cause a lot of problems \n",
    "    dx = v['dx_m']\n",
    "    n = len(h)\n",
    "    elevation = h + h_prime\n",
    "    gradient = np.zeros(len(elevation))\n",
    "    for i in range(1, n - 1):\n",
    "        gradient[i] = (elevation[i + 1] - elevation[i-1]) / (2 * dx)\n",
    "    \n",
    "    # boundary conditions for gradient array\n",
    "    gradient[0] = (elevation[1] - elevation[0]) / dx\n",
    "    gradient[-1] = (elevation[-1] - elevation[-2]) / dx\n",
    "    \n",
    "    diffuse = v['A'] * (h + noZeroMath) ** v['alpha'] * (np.abs(gradient) + noZeroMath) ** v['beta']\n",
    "\n",
    "    # Different way of creating the matricies than the bedrock due to the fact that we have to change them each timestep\n",
    "    # we have to recalculate our \"cD\" each time\n",
    "    lower = np.zeros(n - 1)\n",
    "    mid = np.ones(n)\n",
    "    upper = np.zeros(n - 1)\n",
    "    \n",
    "    for i in range(1, n-1):\n",
    "        D_left = 0.5 * (diffuse[i-1] + diffuse[i])\n",
    "        D_right = 0.5 * (diffuse[i] + diffuse[i+1])\n",
    "        \n",
    "        r_left = 0.5 * v['dt'] * D_left / dx ** 2\n",
    "        r_right = 0.5 * v['dt'] * D_right / dx ** 2\n",
    "        \n",
    "        lower[i-1] = -r_left\n",
    "        mid[i] = 1 + r_left + r_right\n",
    "        upper[i] = -r_right\n",
    "\n",
    "    # creating ML\n",
    "    mid[0] = 1\n",
    "    upper[0] = 0\n",
    "    lower_full = np.zeros(n)\n",
    "    lower_full[1:] = lower\n",
    "\n",
    "    mid_full = mid\n",
    "\n",
    "    upper_full = np.zeros(n)\n",
    "    upper_full[:-1] = upper\n",
    "\n",
    "    ML_Data = np.vstack([lower_full, mid_full, upper_full])\n",
    "    MLdiag = np.array([-1,0,1])\n",
    "    ML = sp.sparse.diags(ML_Data, MLdiag, shape=(n,n)).toarray()\n",
    "\n",
    "    # had to look this up, idk how it works to be honest need to figure that out\n",
    "    lower_MR = -lower\n",
    "    mid_MR = 2 - mid\n",
    "    upper_MR = -upper\n",
    "    \n",
    "\n",
    "    lower_MR_full = np.zeros(n)\n",
    "    lower_MR_full[1:] = lower_MR\n",
    "\n",
    "    mid_MR_full = mid_MR\n",
    "\n",
    "    upper_MR_full = np.zeros(n)\n",
    "    upper_MR_full[:-1] = upper_MR\n",
    "    MR_data = [lower_MR, mid_MR, upper_MR]\n",
    "    MRdiag = np.array([-1,0,1])\n",
    "    MR = sp.sparse.diags(MR_data, MRdiag, shape=(n,n)).toarray()\n",
    "    \n",
    "    MR[0, :] = 0\n",
    "    MR[0, 0] = 1\n",
    "    \n",
    "    return ML, MR\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051992cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solveIceEquation(h, h_prime, time):\n",
    "    ML_Ice, MR_Ice = iceDensity(h, h_prime) # fix this function\n",
    "    G = massBal(h, h_prime, time) # change timestep if needed idk if this is right\n",
    "    RHS = MR_Ice @ h + v['dt'] * G\n",
    "    # need to apply boundary conditions \n",
    "    RHS[0] = 0\n",
    "    h_updated = np.linalg.inv(ML_Ice) @ RHS  # this math might be wrong, check later\n",
    "    return h_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c551465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solveBedrock(h, h_prime):\n",
    "    ML_Bedrock, MR_Bedrock = bedrockM(v['n'])\n",
    "    temp_var = h_prime - v['h_prime0'] + v['r'] * h # makes matrix math easier than it would be otherwise\n",
    "    temp_var[0] = 0\n",
    "    temp_var[-1] = 0\n",
    "    temp_new = np.linalg.inv(ML_Bedrock) @ MR_Bedrock @ temp_var\n",
    "    # do we need to apply boundary conditions here? maybe later\n",
    "    final_hPrime = temp_new + v['h_prime0'] - v['r'] * h\n",
    "    final_hPrime[0] = v['h_prime0'][0]\n",
    "    final_hPrime[-1] = v['h_prime0'][-1]\n",
    "    return final_hPrime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d42e5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the results arrays\n",
    "n_years = 700000 /v['dt']\n",
    "\n",
    "\n",
    "save_interval = 50\n",
    "\n",
    "numSave = int(n_years // save_interval) + 1\n",
    "\n",
    "results_h = np.zeros((numSave, v['n']))\n",
    "results_h_prime = np.zeros((numSave, v['n']))\n",
    "results_time = np.zeros(numSave)\n",
    "results_volume = np.zeros(numSave)\n",
    "\n",
    "current_time = 0.0\n",
    "save_index = 0\n",
    "\n",
    "# main loop, saving all the info from running the functions\n",
    "for step in range(numSave):\n",
    "    time = step * v['dt']\n",
    "    \n",
    "    h_old = v['h'].copy()\n",
    "    h_prime_old = v['h_prime'].copy()\n",
    "    \n",
    "    h_new = solveIceEquation(h_old, h_prime_old, current_time)\n",
    "    \n",
    "    h_avg = 0.5 * (h_old + h_new)\n",
    "    \n",
    "    h_prime_new = solveBedrock(h_avg, h_prime_old)\n",
    "    \n",
    "    v['h'] = h_new\n",
    "    v['h_prime'] = h_prime_new\n",
    "    \n",
    "    if step % save_interval == 0:\n",
    "        results_h[save_index, :] = v['h']\n",
    "        results_h_prime[save_index, :] = v['h_prime']\n",
    "        results_time[save_index] = time\n",
    "        \n",
    "        results_volume[save_index] = np.trapz(v['h'], dx=v['dx_m']) * 3000 / 1e9  # from paper, gets total volume\n",
    "\n",
    "        save_index += 1\n",
    "\n",
    "\n",
    "\n",
    "# Seems like the functions work! maybe the numbers are wrong and thats why the plot isn't correct at all\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(results_time, results_volume, 'b-', linewidth=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fadb1f",
   "metadata": {},
   "source": [
    "The code still isn't completely functional so we don't have any results to discuss yet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
